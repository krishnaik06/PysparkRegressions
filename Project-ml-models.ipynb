{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "        .master('local[*]') \\\n",
    "        .appName('first_spark_application') \\\n",
    "        .getOrCreate() #if there is a active session it will get or create one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data \n",
    "\n",
    "health = spark.read.csv('./data/train.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing categorical data\n",
    "indexer1 = StringIndexer(inputCol='Vehicle_Age',\n",
    "outputCol='Vehicle_Age_idx')\n",
    "\n",
    "indexer2 = StringIndexer(inputCol='Gender',\n",
    "outputCol='Gender_idx')\n",
    "\n",
    "indexer3 = StringIndexer(inputCol='Vehicle_Damage',\n",
    "outputCol='Vehicle_Damage_idx')\n",
    "\n",
    "\n",
    "# now we need to combine all the features in a single list\n",
    "# we are doing this because pyspark.ml what all the features in a list\n",
    "\n",
    "assembler = VectorAssembler(inputCols=['Age', 'Driving_License', \n",
    "                                       'Region_Code', 'Previously_Insured', \n",
    "                                       'Annual_Premium', \n",
    "                                       'Policy_Sales_Channel', 'Vintage', \n",
    "                                       'Vehicle_Age_idx', 'Gender_idx','Vehicle_Damage_idx'],\n",
    "                            outputCol='features')\n",
    "\n",
    "pipeline = Pipeline(stages=[indexer1, indexer2, indexer3, assembler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using pipeline to prepare data for models \n",
    "healthe = pipeline.fit(health).transform(health)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---+---------------+-----------+------------------+-----------+--------------+--------------+--------------------+-------+--------+---------------+----------+------------------+--------------------+\n",
      "| id|Gender|Age|Driving_License|Region_Code|Previously_Insured|Vehicle_Age|Vehicle_Damage|Annual_Premium|Policy_Sales_Channel|Vintage|Response|Vehicle_Age_idx|Gender_idx|Vehicle_Damage_idx|            features|\n",
      "+---+------+---+---------------+-----------+------------------+-----------+--------------+--------------+--------------------+-------+--------+---------------+----------+------------------+--------------------+\n",
      "|  1|  Male| 44|              1|       28.0|                 0|  > 2 Years|           Yes|       40454.0|                26.0|    217|       1|            2.0|       0.0|               0.0|[44.0,1.0,28.0,0....|\n",
      "|  2|  Male| 76|              1|        3.0|                 0|   1-2 Year|            No|       33536.0|                26.0|    183|       0|            0.0|       0.0|               1.0|[76.0,1.0,3.0,0.0...|\n",
      "+---+------+---+---------------+-----------+------------------+-----------+--------------+--------------+--------------------+-------+--------+---------------+----------+------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "healthe.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preparing data for model fitting\n",
    "\n",
    "- We are selecting the features column and response column to get that data needed for predictions\n",
    "\n",
    "- we need to change the output column name to label for the models to work right in spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making the column names as pyspark wants\n",
    "health_ml = healthe.select(['features','Response']).withColumnRenamed('Response', 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[44.0,1.0,28.0,0....|    1|\n",
      "|[76.0,1.0,3.0,0.0...|    0|\n",
      "+--------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "health_ml.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|label| count|\n",
      "+-----+------+\n",
      "|    1| 46710|\n",
      "|    0|334399|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "health_ml.groupby('label').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see we have more values corrospoding to 0 class, so we need to do something to tackel this problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sScaler = StandardScaler(\n",
    "    withMean=True, withStd=True, inputCol=\"features\", outputCol=\"features_scc\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using standard scaler to scale data \n",
    "health_ml = sScaler.fit(health_ml).transform(health_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+\n",
      "|            features|label|        features_scc|\n",
      "+--------------------+-----+--------------------+\n",
      "|[44.0,1.0,28.0,0....|    1|[0.33377683521258...|\n",
      "|[76.0,1.0,3.0,0.0...|    0|[2.39674759709345...|\n",
      "|[47.0,1.0,28.0,0....|    1|[0.52718034413891...|\n",
      "|[21.0,1.0,11.0,1....|    0|[-1.1489833998892...|\n",
      "|[29.0,1.0,41.0,1....|    0|[-0.6332407094190...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "health_ml.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|    1|[0.33377683521258...|\n",
      "|    0|[2.39674759709345...|\n",
      "|    1|[0.52718034413891...|\n",
      "|    0|[-1.1489833998892...|\n",
      "|    0|[-0.6332407094190...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "health_ml = health_ml.drop('features').withColumnRenamed('features_scc', 'features')\n",
    "health_ml.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify a seed for reproducibility\n",
    "# we are spliting the data in test train\n",
    "\n",
    "health_train, health_test = health_ml.randomSplit([0.8, 0.2], seed= 23 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304788 76321\n"
     ]
    }
   ],
   "source": [
    "print(health_train.count(), health_test.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(featuresCol='features', labelCol='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = model.fit(health_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predection = logistic.transform(health_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|    0|[-1.2134512361980...|[1.21186143675719...|[0.77062814310638...|       0.0|\n",
      "|    0|[-1.2134512361980...|[3.59225988362292...|[0.97320188200154...|       0.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predection.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    1|       0.0| 9291|\n",
      "|    0|       0.0|67030|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predection.groupBy(\"label\", \"prediction\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+----------------------------------------+\n",
      "|label|prediction|probability                             |\n",
      "+-----+----------+----------------------------------------+\n",
      "|0    |0.0       |[0.8772294184810425,0.12277058151895744]|\n",
      "|0    |0.0       |[0.8772294184810425,0.12277058151895744]|\n",
      "|0    |0.0       |[0.8772294184810425,0.12277058151895744]|\n",
      "|0    |0.0       |[0.8772294184810425,0.12277058151895744]|\n",
      "|0    |0.0       |[0.8772294184810425,0.12277058151895744]|\n",
      "+-----+----------+----------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the Decision Tree Classifier class\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "# Create a classifier object and fit to the training data\n",
    "tree = DecisionTreeClassifier()\n",
    "tree_model = tree.fit(health_train)\n",
    "\n",
    "# Create predictions for the testing data and take a look at the predictions\n",
    "prediction = tree_model.transform(health_test)\n",
    "prediction.select('label', 'prediction', 'probability').show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    1|       0.0| 9291|\n",
      "|    0|       0.0|67030|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction.groupBy(\"label\", \"prediction\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Params.explainParam of DecisionTreeClassificationModel: uid=DecisionTreeClassifier_44a355ac5c07, depth=0, numNodes=1, numClasses=2, numFeatures=10>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_model.explainParam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
